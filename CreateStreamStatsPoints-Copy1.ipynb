{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Points for StreamStats\n",
    "\n",
    "__Description__:\n",
    "\n",
    "__Input__:\n",
    "\n",
    "__Output__:\n",
    "\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal, ogr,osr\n",
    "from shapely.geometry import Point\n",
    "from StreamStats_Points import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the masked stream grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tif=r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\results\\rock_creek_clip.tif' #Load the stream grid raster which was masked by the catchment polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg: 5070\n"
     ]
    }
   ],
   "source": [
    "sg = StreamGrid(in_tif) #Open the stream grid raster and create an object\n",
    "\n",
    "crs=sg.crs_value() #Extract the coordinate reference system value (epsg) for the raster\n",
    "print(\"epsg:\",crs) #Print the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1205  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   1206  1207  1208  1209  1210  1211  1212  1213  1214  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 1215 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sg.dataframe() #Create a dataframe from the stream grid data\n",
    "df.replace(255, 0, inplace=True) #Replace 255 with 0, where 255 corresponds to the non-stream cells\n",
    "df.head(n=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the pour point to set the start location of the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=1925315.186 #latitude of the pourpoint at the catchment outlet\n",
    "lon=1616784.964 #longitude of the pourpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(877, 1848)]\n"
     ]
    }
   ],
   "source": [
    "pix_x, pix_y =coord2index(sg, lat, lon) #Transform the lat and lon values to the row/column location with the stream grid dataframe\n",
    "pourpoint=[(pix_x, pix_y)] #Add these values to a list as a touple\n",
    "print(pourpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cell Size: 10.0\n"
     ]
    }
   ],
   "source": [
    "cellsize=sg.cell_size() #In meters\n",
    "print(\"The Cell Size:\",cellsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move up the stream and identify the confluences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MoveUpstream(df, stream_cell, nogo):\n",
    "    \"\"\"This function searches the 8 cells surrounding it to determine the location of the next stream cell(s).\n",
    "        Arguments: df=the dataframe containing the stream raster data, stream_cell=the current stream cell that will be used to search for the next stream cell,\n",
    "        nogo=list of stream cells that do not want to return as a new stream cell\n",
    "    \"\"\"\n",
    "    row=stream_cell[0] #Extract the raster row \n",
    "    col=stream_cell[1] #Extract the raster column\n",
    "    cell_value= df[row][col] #Determine the value of the cell\n",
    "    \n",
    "    assert cell_value == 1, \"The provided cell in MoveUpstream is not a stream cell\" #The value of the cell must be equal to the value associated with a stream cell\n",
    "    \n",
    "    nogo.append((row,col))   \n",
    "\n",
    "    stream_cell=[]\n",
    "    \n",
    "    for i in range(-1,2): #For -1, 0, 1 in the vertical direction (move up and down rows)\n",
    "        for j in range(-1,2): #For -1, 0, 1 in the horizontal direction (move across columns)\n",
    "            value = df[row + i][col+j] #Read value of raster cell\n",
    "            if value == 0: # if value is zero, no stream in this cell\n",
    "                continue #loop back\n",
    "            elif value==1 and (row+i,col+j) not in nogo: # if value is 1 and the cell is not in the nogo list, then...\n",
    "                stream_cell.append((row + i,col+j)) #Add the new cell or cells to the stream_cell list\n",
    "                \n",
    "    return stream_cell, nogo    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindConfluence(df, stream_cell, nogo, mainstem, dis, DisExl): #Keep moving upstream until you find a confluence--problem: might hit a dead end, maybe add an else if it is the end?\n",
    "    \"\"\"Function which repeates the MoveUpstream function until it finds two or more stream cells surrounding the provided stream_cell, indicating a confluence\n",
    "    \"\"\"\n",
    "    assert len(stream_cell)==1, \"Multiple stream cells passed to FindConfluence Function\"\n",
    "    \n",
    "    while len(stream_cell)==1: #While there is only 1 stream cell returned as we move up stream, keep moving up stream\n",
    "        cell1=stream_cell[0]\n",
    "        stream_cell, nogo=MoveUpstream(df, stream_cell[0], nogo)\n",
    "        if len(stream_cell)>=1:\n",
    "            cell2=stream_cell[0]  \n",
    "            cell_dis=TrueDistance(cell1, cell2, cellsize)\n",
    "            dis=dis+cell_dis\n",
    "            dis_lower=dis/DisExl-(10.0*np.sqrt(2))/DisExl\n",
    "            dis_upper=dis/DisExl+(10.0*np.sqrt(2))/DisExl  \n",
    "            if dis_lower<=int(dis/DisExl)<=dis_upper and cell1 not in mainstem:\n",
    "                mainstem.append(stream_cell[0])\n",
    "    if len(stream_cell)>1: #If the number of stream cells \n",
    "        nogo=list(set(nogo+stream_cell))\n",
    "        \n",
    "    return stream_cell, nogo, mainstem, dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckTribDis(stream_cell, nogo, dis, DisExl):\n",
    "    \"\"\"Check to see if the tributary has a confluence, if it does not and is not long enough, then remove it \n",
    "    \"\"\"\n",
    "    nogo_temp=nogo.copy()\n",
    "    mainstem_temp=[]\n",
    "    remove=[]\n",
    "\n",
    "    for cell in stream_cell:\n",
    "        dis_temp=dis.copy()\n",
    "        stream_cell1, nogo_temp, mainstem_temp, dis_temp=FindConfluence(df, [cell], nogo_temp, mainstem_temp, dis_temp, DisExl)\n",
    "        if len(stream_cell1)==0 and dis_temp<DisExl:\n",
    "            remove.append(cell)\n",
    "            \n",
    "    stream_cell=list(set(stream_cell) - set(remove))\n",
    "    return stream_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckConfluence(df, stream_cell, nogo, mainstem, dis, DisExl):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert len(stream_cell)==1, \"Multiple stream cells passed to CheckConfluence Function\"\n",
    "    \n",
    "    while len(stream_cell)==1:\n",
    "        stream_cell, nogo, mainstem, dis=FindConfluence(df, stream_cell, nogo, mainstem, dis, DisExl)\n",
    "        if len(stream_cell)>1:\n",
    "            stream_cell=CheckTribDis(stream_cell, nogo, dis, DisExl)\n",
    "        #if len==0? Then end of network?\n",
    "        \n",
    "    return stream_cell, nogo, mainstem, dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddConfluencetoDict(df, confl, nogo, mainstem, dis, DisExl, Incl_Confl):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    IC_key=max(list(Incl_Confl.keys()))+1\n",
    "    dis_confl=dis.copy()\n",
    "\n",
    "    for i in range(len(confl)):\n",
    "        dis_temp=dis.copy()\n",
    "        mainstem_temp=[]\n",
    "        \n",
    "        stream_cell, nogo, mainstem_temp, dis_temp=CheckConfluence(df, [confl[i]], nogo, mainstem_temp, dis_temp, DisExl)\n",
    "        \n",
    "        if len(stream_cell)==0 and (dis_temp-dis_confl)>=DisExl:\n",
    "            Incl_Confl[IC_key]={'cell':confl, 'dis':dis_confl}\n",
    "        if len(stream_cell)>1:\n",
    "            dis_out=dis_temp.copy()\n",
    "            next_confl=stream_cell\n",
    "            mainstem=mainstem+mainstem_temp\n",
    "    return next_confl, nogo, mainstem, dis_out, Incl_Confl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set parameters and intalize objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogo=[] #Empty list to store the nogo points, i.e. the stream cells we previously searched\n",
    "mainstem=[]\n",
    "\n",
    "dis=0.0\n",
    "DisExl=(5280/2.0)/3.28084 #1/2 mile in In meters\n",
    "\n",
    "Incl_Confl=collections.OrderedDict()\n",
    "Incl_Confl[0]={'cell':pourpoint, 'dis':dis}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the initial confluence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(880, 1786), (879, 1786)] 757.6955262170047\n"
     ]
    }
   ],
   "source": [
    "stream_cell=pourpoint\n",
    "\n",
    "confl, nogo, mainstem, dis=CheckConfluence(df, stream_cell, nogo, mainstem, dis, DisExl) \n",
    "\n",
    "print(confl, dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine if the initial confluence should be saved, find the next confluence, and repeat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "confl, nogo, mainstem, dis, Incl_confl=AddConfluencetoDict(df, confl, nogo, mainstem, dis, DisExl, Incl_Confl)\n",
    "print(confl, dis)\n",
    "\n",
    "#####Comeback to issue with distance up tributaries with multiple points. tried adding dis to checktrib but may have messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(893, 1742), (892, 1742)] 1247.4011537017768\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_key=max(list(Incl_Confl.keys()))+1\n",
    "dis_confl=dis.copy()\n",
    "\n",
    "i=1\n",
    "dis_temp=dis.copy()\n",
    "mainstem_temp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_cell, nogo, mainstem, dis_temp=FindConfluence(df, [confl[i]], nogo, mainstem, dis_temp, DisExl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(836, 1585), (836, 1586), (837, 1584)] 461.1269837220834\n"
     ]
    }
   ],
   "source": [
    "print(stream_cell, dis_temp-dis_confl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_cell=CheckTribDis(stream_cell, nogo, DisExl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "if len(stream_cell)==0 and (dis_temp-dis_confl)>=DisExl:\n",
    "    Incl_Confl[IC_key]={'cell':confl, 'dis':dis_confl}\n",
    "if len(stream_cell)>1:\n",
    "    dis_out=dis_temp.copy()\n",
    "    next_confl=stream_cell\n",
    "    mainstem=mainstem+mainstem_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'next_confl' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-000d64a1d57b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mconfl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnogo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainstem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIncl_confl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAddConfluencetoDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnogo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainstem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDisExl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIncl_Confl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-2c24b37c4478>\u001b[0m in \u001b[0;36mAddConfluencetoDict\u001b[1;34m(df, confl, nogo, mainstem, dis, DisExl, Incl_Confl)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mnext_confl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mmainstem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmainstem\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmainstem_temp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnext_confl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnogo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainstem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIncl_Confl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'next_confl' referenced before assignment"
     ]
    }
   ],
   "source": [
    "while len(confl)>1:\n",
    "    confl, nogo, mainstem, dis, Incl_confl=AddConfluencetoDict(df, confl, nogo, mainstem, dis, DisExl, Incl_Confl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the stream cells to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "confl_lst=[]\n",
    "dist_lst=[]\n",
    "\n",
    "for v in Incl_Confl.values():\n",
    "    confl_lst=confl_lst+v['cell']\n",
    "    dist_lst=dist_lst+list(np.ones(len(v['cell']))*v['dis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the list of stream cells to a shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sputnam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n"
     ]
    }
   ],
   "source": [
    "longitude, latitude=index2coord(sg, confl_lst)\n",
    "gdf=geodataframe(longitude, latitude, crs, dist_lst)\n",
    "gdf.to_file(filename = r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\results\\Confl.shp')\n",
    "\n",
    "longitude, latitude=index2coord(sg, mainstem)\n",
    "gdf=geodataframe(longitude, latitude, crs)\n",
    "gdf.to_file(filename = r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\results\\mainstem.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
