{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pathlib as pl\n",
    "sys.path.append('../Core')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The state abbreviation in uppercase\n",
    "state = 'NY' \n",
    "\n",
    "#Specify the location of the shapefile/json containing the lat/lon of points on the stream grid\n",
    "path = pl.Path(r'P:\\Temp\\jMatney\\R2_RII\\json')\n",
    "name = 'riv_gauges_parsed.json' #The name of the shapefile/json\n",
    "\n",
    "#Specify a consistent coordinate reference system\n",
    "use_epsg = '4326' \n",
    "\n",
    "#Location to save the StreamStats results for each polygon\n",
    "allresults = os.path.join(path,'AllStreamStats') \n",
    "if os.path.isdir(allresults) == False: \n",
    "    os.mkdir(allresults)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 gages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'id': 0,\n",
       " 'geometry': {'type': 'Point', 'coordinates': [-75.33027778, 39.64388889]},\n",
       " 'properties': {'FID': 0,\n",
       "  'State': 'NJ',\n",
       "  'Gauge_Name': 'Salem River At Woodstown Nj',\n",
       "  'X': 39.643889,\n",
       "  'Y': -75.330278,\n",
       "  'Gauge_No': '01482500'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path/name) as f:\n",
    "    dic = json.load(f)\n",
    "print('{0} gages'.format(len(dic['features'])))    \n",
    "dic['features'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select for state of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 gages for NY\n"
     ]
    }
   ],
   "source": [
    "select = {}\n",
    "for feature in dic['features']:\n",
    "    if feature['properties']['State'] == state:\n",
    "        select[feature['properties']['Gauge_No']] = feature['geometry']['coordinates']\n",
    "print('{0} gages for {1}'.format(len(list(select.keys())), state))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store the catchment polygons (catchment boundaries) \n",
    "polyg = {} \n",
    "\n",
    "#Dictionary to store the outlet flow frequency data dictionaries\n",
    "ffdata = {} \n",
    "\n",
    "get_flow = False\n",
    "print_status = True\n",
    "if state=='WI': \n",
    "    get_flow = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/Lon/Confluence: 42.03527778 -75.8030556 01503000\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for ID_Num, geom in select.items():\n",
    "    try:\n",
    "        #Longitude and latitude for each shapely point and the confluence number\n",
    "        lon, lat = geom[0], geom[1]\n",
    "        if print_status: \n",
    "            print(\"Lat/Lon/Confluence:\", lat, lon, ID_Num)\n",
    "            \n",
    "        #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "        polyg[ID_Num], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) \n",
    "        if get_flow: \n",
    "            #Use the function above to extract the json data\n",
    "            ffdata[ID_Num]                           = get_peaks(ff_json) \n",
    "            polyg[ID_Num]['features'][0]['ffcurve']  = ffdata[ID_Num]\n",
    "        \n",
    "        with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(int(ID_Num))), 'w') as f:\n",
    "            dump(polyg[ID_Num], f)\n",
    "    except:\n",
    "        print('could not process data {}'.format(ID_Num))\n",
    "        errors.append(ID_Num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files(allresults)\n",
    "gdf2, ffdic=load_results(files, use_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.drop(gdf.loc[gdf['Id'][gdf2['ID_Num']]].index, inplace=True)\n",
    "gdf.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this function to construct the summary table for all outlet locations\n",
    "if get_flow: ff_df=ff_summary(ffdic) \n",
    "    \n",
    "#Save the results as a csv\n",
    "if get_flow: ff_df.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the geodataframe as a shapefile\n",
    "gdf2 = convert_attr(gdf2)\n",
    "gdf2.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf2, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
