{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../USGStools')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The state abbreviation in uppercase\n",
    "state='NY' \n",
    "\n",
    "#Specify the location of the shapefile containing the lat/lon of points on the stream grid\n",
    "path=r'C:\\Users\\tmiesse\\Desktop\\bridges' \n",
    "name='Bridges_StreamStatSnap.shp' #The name of the shapefile\n",
    "\n",
    "#Specify a consistent coordinate reference system\n",
    "use_epsg='4326' \n",
    "\n",
    "#Location to save the StreamStats results for each polygon\n",
    "allresults=os.path.join(path,'AllStreamStats') \n",
    "if os.path.isdir(allresults)==False: \n",
    "    os.mkdir(allresults)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the shapefile as a geopandas dataframe\n",
    "#Transform the coordinate reference system of the geodataframe\n",
    "gdf=gpd.read_file(os.path.join(path, name)) \n",
    "gdf=gdf.to_crs({'init': 'epsg:{0}'.format(use_epsg)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.index = gdf['Id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store the catchment polygons (catchment boundaries) \n",
    "polyg={} \n",
    "\n",
    "#Dictionary to store the outlet flow frequency data dictionaries\n",
    "ffdata={} \n",
    "\n",
    "get_flow=True\n",
    "print_status=True\n",
    "if state=='WI': get_flow=False \n",
    "errors = [0]\n",
    "count = {i:0 for i in gdf['Id']}\n",
    "keys = count.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/Lon/Confluence: 44.49430728613341 -74.87051208078036 122\n",
      "Fetched Peak Flows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#while errors != [] and [count[key] > 3 for key in keys]:\n",
    "    errors = []\n",
    "    for i in gdf.index.values:\n",
    "        try:\n",
    "            #Longitude and latitude for each shapely point and the confluence number\n",
    "            lon, lat, ID_Num = gdf.geometry[i].x, gdf.geometry[i].y, gdf['Id'][i] \n",
    "            if print_status: print(\"Lat/Lon/Confluence:\", lat, lon, ID_Num)\n",
    "                \n",
    "            #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "            polyg[ID_Num], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) \n",
    "            if get_flow: \n",
    "                #Use the function above to extract the json data\n",
    "                ffdata[ID_Num]                           = get_peaks(ff_json) \n",
    "                polyg[ID_Num]['features'][0]['ffcurve']  = ffdata[ID_Num]\n",
    "            \n",
    "            with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(int(ID_Num))), 'w') as f:\n",
    "                dump(polyg[ID_Num], f)\n",
    "        except:\n",
    "            print('could not process data {}'.format(gdf['Id'][i]))\n",
    "            errors.append(gdf['Id'][i]) \n",
    "            count[gdf['Id'][i]] += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 Polygon Files Found\n"
     ]
    }
   ],
   "source": [
    "files=load_files(allresults)\n",
    "gdf2, ffdic=load_results(files, use_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.drop(gdf.loc[gdf['Id'][gdf2['ID_Num']]].index, inplace=True)\n",
    "gdf.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1          10         100          101  \\\n",
      "RI                                                                   \n",
      "1.25  2722.476473  105.367471  371.134293  138.411019   587.438697   \n",
      "1.5   3131.739667  127.123751  440.892592  167.686939   698.958181   \n",
      "2.0   3631.339930  155.821593  531.378270  206.309984   842.119320   \n",
      "5.0   4949.987856  234.758003  777.472063  312.073232  1227.785959   \n",
      "10.0  5852.257050  292.375717  957.029999  388.026610  1500.246808   \n",
      "\n",
      "             102          103          104          105         106  ...  \\\n",
      "RI                                                                   ...   \n",
      "1.25  222.689392   630.967702   521.398561   423.581278  302.410724  ...   \n",
      "1.5   268.155301   758.453009   626.716159   509.534927  364.508898  ...   \n",
      "2.0   327.444645   923.917443   761.759774   620.265057  445.150642  ...   \n",
      "5.0   489.072720  1373.053460  1128.332168   921.317926  665.009716  ...   \n",
      "10.0  604.588797  1693.643605  1386.394517  1134.304568  821.700665  ...   \n",
      "\n",
      "              90          91          92            93           94  \\\n",
      "RI                                                                    \n",
      "1.25   80.035180  335.904654  252.772246   4981.753852  1389.237351   \n",
      "1.5    97.138523  404.483822  304.877877   5713.399888  1648.950598   \n",
      "2.0   119.879396  493.266508  372.295163   6601.635477  1978.406501   \n",
      "5.0   182.254713  735.040037  556.857152   8933.813462  2862.202016   \n",
      "10.0  227.157561  906.852462  688.830076  10521.340799  3481.475986   \n",
      "\n",
      "               95           96            97           98          99  \n",
      "RI                                                                     \n",
      "1.25   694.946993  1295.227055   5273.558033   657.830892  233.624508  \n",
      "1.5    833.597171  1549.047679   6085.183982   790.726568  281.209960  \n",
      "2.0   1012.733684  1873.886424   7075.182807   962.846486  343.215629  \n",
      "5.0   1497.251770  2750.011973   9679.082846  1429.065302  512.200859  \n",
      "10.0  1840.281348  3367.922277  11454.926209  1759.492952  632.963692  \n",
      "\n",
      "[5 rows x 337 columns]\n"
     ]
    }
   ],
   "source": [
    "#Run this function to construct the summary table for all outlet locations\n",
    "if get_flow: ff_df=ff_summary(ffdic) \n",
    "    \n",
    "#Save the results as a csv\n",
    "if get_flow: ff_df.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmiesse\\AppData\\Local\\Continuum\\anaconda3\\envs\\geoprocess\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n"
     ]
    }
   ],
   "source": [
    "#Export the geodataframe as a shapefile\n",
    "gdf2 = convert_attr(gdf2)\n",
    "gdf2.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf2, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geoprocess]",
   "language": "python",
   "name": "conda-env-geoprocess-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
