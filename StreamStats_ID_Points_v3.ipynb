{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Points for StreamStats\n",
    "\n",
    "__Description__: Tool to identify confluence pair points for tributaries of a specific length, add points to the main stem of a stream network at a specific distance interval, and export a shapefile of the points. For additional details, see the [StreamStats Automation Wiki](https://github.com/Dewberry/usgs-tools/wiki/StreamStats-Automation).\n",
    "\n",
    "__Input__: Stream grid from the [SteamStats Repository](https://streamstatsags.cr.usgs.gov/StreamGrids/directoryBrowsing.asp), masked using `ClipRaster_withMask.ipynb` and the latitude and longitude of the catchment outlet.\n",
    "\n",
    "__Output__: A shapefile containing the latitude and longitude of points (confluence and main stem locations) that will be used as the input to `StreamStats_API_Scraper_Auto.ipynb`.\n",
    "\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal, ogr,osr\n",
    "from shapely.geometry import Point\n",
    "from StreamStats_Points import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the masked stream grid:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\results\\Rock_Creek.tif' #Load the stream grid raster which was masked by the catchment polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg: 5070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1205  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   1206  1207  1208  1209  1210  1211  1212  1213  1214  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 1215 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg = StreamGrid(path) #Open the stream grid raster and create an object\n",
    "\n",
    "crs=sg.crs_value() #Extract the coordinate reference system value (epsg) for the raster\n",
    "print(\"epsg:\",crs) \n",
    "\n",
    "df = sg.dataframe() #Create a dataframe from the stream grid data\n",
    "df.replace(255, 0, inplace=True) #Replace 255 with 0, where 255 corresponds to the non-stream cells\n",
    "df.head(n=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the pour point to set the start location of the search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=1925315.186 #latitude of the pourpoint at the catchment outlet\n",
    "lon=1616784.964 #longitude of the pourpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert the lat/lon to row/column in the stream grid dataframe and extract the cell size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourpoint XY: [(877, 1848)]\n",
      "The Cell Size: 10.0\n"
     ]
    }
   ],
   "source": [
    "pix_x, pix_y =coord2index(sg, lat, lon) #Transform the lat and lon values to the row/column location with the stream grid dataframe\n",
    "pourpoint=[(pix_x, pix_y)] #Add these values to a list as a touple\n",
    "print(\"Pourpoint XY:\", pourpoint)\n",
    "\n",
    "cellsize=sg.cell_size() #Raster cell size in meters\n",
    "print(\"The Cell Size:\", cellsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move up the stream and identify the confluences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify parameters and intalize objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogo=[] #Empty list to store the stream cells that we do not want to return to since we have already searched them\n",
    "confluence_pairs=[] #Empty list to store the identified confluence pairs\n",
    "save_confluence=[] #Empty list to store the location of confluences that are three cells away from the original confluence location\n",
    "cnum=0 #The confluence number or ID\n",
    "count=0 #Counting variable. The number of times we have looped over the while loop below\n",
    "\n",
    "starting_point=pourpoint[0]+(cnum,) #The starting point of the stream network where we want to start searching for confluences. Add the confluence number\n",
    "\n",
    "nogo.append(starting_point) #Add the starting point to the no go list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify confluences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogo=[] #Empty list to store the stream cells that we do not want to return to since we have already searched them\n",
    "confluence_pairs=[] #Empty list to store the identified confluence pairs\n",
    "save_confluence=[] #Empty list to store the location of confluences that are three cells away from the original confluence location\n",
    "cnum=0 #The confluence number or ID\n",
    "count=0 #Counting variable. The number of times we have looped over the while loop below\n",
    "\n",
    "starting_point=pourpoint[0]+(cnum,) #The starting point of the stream network where we want to start searching for confluences. Add the confluence number\n",
    "\n",
    "nogo.append(starting_point) #Add the starting point to the no go list\n",
    "\n",
    "while len(starting_point)>0:\n",
    "    count+=1\n",
    "    cnum=count\n",
    "    \n",
    "    next_cell=MoveUpstream(df, starting_point, nogo, cnum)  \n",
    "    \n",
    "    if len(next_cell) == 1:\n",
    "        nogo.append(next_cell[0])\n",
    "        starting_point = next_cell[0]\n",
    "        \n",
    "    else:\n",
    "        if len(next_cell)>1:\n",
    "            nogo=nogo+next_cell\n",
    "            confluence_pairs=confluence_pairs+next_cell\n",
    "        if len(confluence_pairs)>0:\n",
    "            starting_point=confluence_pairs[0]\n",
    "            confluence_pairs.remove(starting_point)\n",
    "            cnum=starting_point[2]\n",
    "            \n",
    "            i=0\n",
    "            while i<2:\n",
    "                next_cell=MoveUpstream(df, starting_point, nogo, cnum)\n",
    "                \n",
    "                if len(next_cell) == 1:\n",
    "                    nogo.append(next_cell[0])\n",
    "                    starting_point = next_cell[0]\n",
    "                    i+=1\n",
    "                    continue\n",
    "                elif len(next_cell)>1:\n",
    "                    confluence_pairs=confluence_pairs+next_cell\n",
    "                    i=2\n",
    "                else:\n",
    "                    i=2\n",
    "                \n",
    "            if len(next_cell) == 1:\n",
    "                save_confluence.append(starting_point)\n",
    "        else:\n",
    "            starting_point=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove superflous confluences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Points: 614 True Confluences: 475\n"
     ]
    }
   ],
   "source": [
    "true_confluence=[] #Empty list to store the true confluences, i.e. those that are not just two stream cells next to eachother\n",
    "confl_num=[] #List to store the extracted confluence numbers\n",
    "\n",
    "for cell in save_confluence: #For each stream cell, add the confluence number to a list\n",
    "    confl_num.append(cell[2])\n",
    "\n",
    "for cell in save_confluence: #For each stream cell, if there are two or more stream cells with the same confluence number, i.e it is a confluence, add to the true_confluence list.\n",
    "    if confl_num.count(cell[2])>=2:\n",
    "        true_confluence.append(cell)\n",
    "        \n",
    "false_confluence=list(set(save_confluence)-set(true_confluence)) #List of cells that were identified as confluences but do not have tributaries\n",
    "\n",
    "print(\"All Points:\", len(save_confluence), \"True Confluences:\", len(true_confluence))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify the original superflous confluence location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_cnum=[]\n",
    "false_points=[]\n",
    "\n",
    "for cell in false_confluence:\n",
    "    false_cnum.append(cell[2])\n",
    "\n",
    "for cell in nogo:\n",
    "    if cell[2] in false_cnum:\n",
    "        false_points.append(cell)\n",
    "        \n",
    "false_points=list(set(false_points)-set(false_confluence))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the tributary length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify parameters and intalize objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tributary=[] \n",
    "mainstem=[]\n",
    "\n",
    "walk_confluence=true_confluence.copy() #Copy the true_confluence list, since we want to walk upstream of these to calculate the length to the end of the trib or next confluence\n",
    "nogo=[walk_confluence[0]]\n",
    "starting_point=walk_confluence[0] #Assign the first confluence point to the starting_point\n",
    "\n",
    "total_dis=0.0 #The total distance from the confluence point\n",
    "count=1\n",
    "repeat=0\n",
    "\n",
    "false_pointswocnum=remove_cnum(false_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nogoabs=nogo.copy()\n",
    "\n",
    "while len(walk_confluence)>0:\n",
    "        next_cell=MoveUpstream(df, starting_point, nogo)\n",
    "        \n",
    "        if len(next_cell)==1 or len(next_cell)>1 and count==1:\n",
    "            step_dis=TrueDistance(starting_point, next_cell[0], cellsize)\n",
    "            total_dis=step_dis+total_dis\n",
    "            nogo.append(next_cell[0])\n",
    "            starting_point = next_cell[0]\n",
    "            count+=1\n",
    "            continue\n",
    " \n",
    "        elif len(next_cell)>1 and 1<count<=4:\n",
    "            next_cellwocnum=remove_cnum(next_cell)\n",
    "            if any(x in next_cellwocnum for x in false_pointswocnum): #If any of the cells in next_cell are in false_confluence, then find that cell and assign it to next cell\n",
    "                nogo=nogo+next_cell\n",
    "                for cell in next_cell:\n",
    "                    test_cell=MoveUpstream(df, cell, nogo)\n",
    "                    if len(test_cell)==0:\n",
    "                        next_cell.remove(cell)\n",
    "                step_dis=TrueDistance(starting_point, next_cell[0], cellsize)\n",
    "                total_dis=step_dis+total_dis\n",
    "                starting_point=next_cell[0]\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                if repeat==0:\n",
    "                    total_dis=0.0\n",
    "                    starting_point = walk_confluence[0]\n",
    "                    count=1\n",
    "                    repeat=1\n",
    "                else:\n",
    "                    step_dis=TrueDistance(starting_point, next_cell[0], cellsize)\n",
    "                    total_dis=step_dis+total_dis\n",
    "                    mainstem.append(walk_confluence[0]+(total_dis,))\n",
    "                    walk_confluence.remove(walk_confluence[0])\n",
    "                    if len(walk_confluence)>0:\n",
    "                        total_dis=0.0\n",
    "                        nogoabs=nogoabs+nogo\n",
    "                        starting_point=walk_confluence[0]                        \n",
    "                        nogo=[starting_point]\n",
    "                        repeat=0\n",
    "                        count=1\n",
    "                    else:\n",
    "                        walk_confluence=[] \n",
    "            \n",
    "        elif len(next_cell)>1 and count>4:    \n",
    "            next_cellwocnum=remove_cnum(next_cell)\n",
    "            if any(x in next_cellwocnum for x in false_pointswocnum): #If any of the cells in next_cell are in false_confluence, then find that cell and assign it to next cell\n",
    "                nogo=nogo+next_cell\n",
    "                for cell in next_cell:\n",
    "                    test_cell=MoveUpstream(df, cell, nogo)\n",
    "                    if len(test_cell)==0:\n",
    "                        next_cell.remove(cell)\n",
    "                step_dis=TrueDistance(starting_point, next_cell[0], cellsize)\n",
    "                total_dis=step_dis+total_dis\n",
    "                starting_point=next_cell[0]\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                step_dis=TrueDistance(starting_point, next_cell[0], cellsize)\n",
    "                total_dis=step_dis+total_dis\n",
    "                mainstem.append(walk_confluence[0]+(total_dis,))\n",
    "                walk_confluence.remove(walk_confluence[0])\n",
    "                if len(walk_confluence)>0:\n",
    "                    total_dis=0.0\n",
    "                    nogoabs=nogoabs+nogo\n",
    "                    starting_point=walk_confluence[0]\n",
    "                    nogo=[starting_point]\n",
    "                    repeat=0\n",
    "                    count=1\n",
    "                else:\n",
    "                    walk_confluence=[] \n",
    "                    \n",
    "        elif len(next_cell)==0:\n",
    "            tributary.append(walk_confluence[0]+(total_dis,))\n",
    "            walk_confluence.remove(walk_confluence[0])\n",
    "            if len(walk_confluence)>0:\n",
    "                total_dis=0.0\n",
    "                nogoabs=nogoabs+nogo\n",
    "                starting_point=walk_confluence[0]\n",
    "                nogo=[starting_point]\n",
    "                repeat=0\n",
    "                count=1\n",
    "            else:\n",
    "                walk_confluence=[]\n",
    "                \n",
    "nogoabs=list(set(nogoabs))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mainstem)+len(tributary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mainstem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove confluences with tributaries less than specific length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "disexl=(5280/2.0)*(0.3048)\n",
    "\n",
    "incl_tribs=[]\n",
    "\n",
    "for cell in tributary:\n",
    "    if cell[3]>=disexl:\n",
    "        incl_tribs.append(cell) \n",
    "\n",
    "print(len(incl_tribs))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the confluence number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum_mainstem=[]\n",
    "cnum_tributary=[]\n",
    "\n",
    "for cell in mainstem:\n",
    "    cnum_mainstem.append(cell[2])\n",
    "\n",
    "for cell in tributary:\n",
    "    cnum_tributary.append(cell[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_tribs=[]\n",
    "\n",
    "for cell in tributary:\n",
    "    dis_tribs.append(cell[3])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform and save as a shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=[save_confluence, true_confluence, mainstem, tributary, false_points, nogoabs, incl_tribs]\n",
    "names=['save_confluence', 'true_confluence', 'mainstem', 'tributary', 'false_points', 'nogo', 'incl_tribs']\n",
    "distance=[[],[],[],dis_tribs,[],[],[]]\n",
    "cnums=[[],[],cnum_mainstem,cnum_tributary,[],[],[]]\n",
    "\n",
    "for i in range(len(lists)):\n",
    "    longitude, latitude=index2coord(sg, lists[i])  #Transform the row/column value from the stream grid dataframe to latitude/longitude for each confluence\n",
    "    gdf=geodataframe(longitude, latitude, crs, distance[i],cnums[i]) #Store the longitude/latitude for each confluence in a geodataframe\n",
    "    gdf.to_file(filename = r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\results\\{}.shp'.format(names[i])) #Export the geodataframe as a shapefule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
