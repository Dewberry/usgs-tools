{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../USGStools')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state='WI' #The state abbreviation in uppercase\n",
    "\n",
    "path=r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\StreamStats\\results\\Kewaunee_WI' #Specify the location of the shapefile containing the lat/lon of points on the stream grid\n",
    "\n",
    "name='Confluences1.shp' #The name of the shapefile\n",
    "\n",
    "use_epsg='4326' #Specify a consistent coordinate reference system\n",
    "\n",
    "allresults=os.path.join(path,'AllStreamStats') #Location to save the StreamStats results for each polygon\n",
    "\n",
    "if os.path.isdir(allresults)==False: #If the desired path does not exist, create it.\n",
    "    os.mkdir(allresults)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num\n",
      "0    POINT (-87.43693610883072 44.62174776562063)\n",
      "1    POINT (-87.44794369555855 44.61893847649607)\n",
      "Name: geometry, dtype: object\n"
     ]
    }
   ],
   "source": [
    "gdf=gpd.read_file(os.path.join(path, name)) #Read the shapefile as a geopandas dataframe\n",
    "\n",
    "gdf=gdf.set_index('num').copy(deep=True) #Set the index to the confluence number\n",
    "\n",
    "gdf=gdf.to_crs({'init': 'epsg:{0}'.format(use_epsg)}) #Transform the coordinate reference system of the geodataframe\n",
    "\n",
    "geom=gdf.geometry #Extract the shapley geometry for the outlets in the shapefile\n",
    "\n",
    "print(geom.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/Lon: 44.62174776562063 -87.43693610883072\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61893847649607 -87.44794369555855\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61733078041878 -87.4439636656148\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61630613512092 -87.44485448366903\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61137850788752 -87.44814234295116\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61023281626847 -87.44714673613238\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61223172253167 -87.44879475329016\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61491013410794 -87.45682264909334\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.613788682486 -87.45620412197006\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61003057024509 -87.46086408663705\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.611659297149366 -87.46940530632472\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61860761074862 -87.47232940506365\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.622704213198496 -87.47295214736857\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.608799164134155 -87.47965537960289\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.62658083465956 -87.4743636263028\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.625824248962324 -87.47522016451903\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.6066981235119 -87.48486482410375\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.60796400994482 -87.48774730373437\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.60547056283731 -87.49528762700906\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.61462275261483 -87.48614557655216\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.618327256935366 -87.4891007939567\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.623837469207054 -87.49068718055281\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.628054446085464 -87.49319794033651\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.631635022772635 -87.49845235038705\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.62896871630897 -87.50753826686532\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.62852430607379 -87.51330040304342\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.62525264679127 -87.51713593538356\n",
      "Fetched Peak Flows\n",
      "Lat/Lon: 44.62590500142212 -87.52314005565428\n",
      "Fetched Peak Flows\n"
     ]
    }
   ],
   "source": [
    "polyg={} #Dictionary to store the catchment polygons (catchment boundaries) \n",
    "\n",
    "ffdata={} #Dictionary to store the outlet flow frequency data dictionaries\n",
    "\n",
    "if state=='WI': get_flow=False \n",
    "print_status=True\n",
    "\n",
    "for i, xy in enumerate(geom): #For gdf.geometry:\n",
    "    lon, lat = xy.x, xy.y #Longitude and latitude for each shapely point\n",
    "    if print_status==True:\n",
    "        print(\"Lat/Lon:\", lat, lon)\n",
    "    polyg[i], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "    if get_flow: \n",
    "        ffdata[i]= get_peaks(ff_json) #Use the function above to extract the json data\n",
    "        polyg[i]['features'][0]['ffcurve']=ffdata[i]\n",
    "    with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(gdf.index[i])), 'w') as f:\n",
    "       dump(polyg[i], f)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_files=[] #Empty list to store the geojson paths\n",
    "\n",
    "poly_files=load_all_results(allresults)\n",
    "\n",
    "gdf=gpd.GeoDataFrame(crs={'init': 'epsg:{}'.format(use_epsg)})\n",
    "                          \n",
    "for _,filename in enumerate(poly_files):\n",
    "    num=re.findall('\\d+', filename)\n",
    "    temp_df=gpd.read_file(filename)\n",
    "    #temp_df['ID_Name']='Algoma'\n",
    "    temp_df['ID_Num']=int(num[0])\n",
    "    gdf=gdf.append(temp_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_flow: ffdata=ff_summary(pp_dic) #Run this function to construct the summary table for all outlet locations\n",
    "    \n",
    "if get_flow: ffdata.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) #Save the results as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) #Export the geodataframe as a shapefule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
