{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../USGStools')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state='NY' #The state abbreviation in uppercase\n",
    "\n",
    "path=r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\StreamStats\\results\\04150303' #Specify the location of the shapefile containing the lat/lon of points on the stream grid\n",
    "\n",
    "name='04150303_Confluences_Scoped.shp' #The name of the shapefile\n",
    "\n",
    "use_epsg='4326' #Specify a consistent coordinate reference system\n",
    "\n",
    "allresults=os.path.join(path,'AllStreamStats') #Location to save the StreamStats results for each polygon\n",
    "\n",
    "if os.path.isdir(allresults)==False: #If the desired path does not exist, create it.\n",
    "    os.mkdir(allresults)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gpd.read_file(os.path.join(path, name)) #Read the shapefile as a geopandas dataframe\n",
    "\n",
    "gdf=gdf.to_crs({'init': 'epsg:{0}'.format(use_epsg)}) #Transform the coordinate reference system of the geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyg={} #Dictionary to store the catchment polygons (catchment boundaries) \n",
    "\n",
    "ffdata={} #Dictionary to store the outlet flow frequency data dictionaries\n",
    "\n",
    "get_flow=True\n",
    "print_status=True\n",
    "\n",
    "if state=='WI': get_flow=False \n",
    "\n",
    "start_confluence=0 #The confluence number to start. Normally set to zero unless there was an issue   \n",
    "stop_confluence=100\n",
    "\n",
    "for i in gdf[gdf[gdf['num']==start_confluence].index[0]:gdf[gdf['num']==stop_confluence].index[0]+1].index:\n",
    "    lon, lat, num = gdf.geometry[i].x, gdf.geometry[i].y, gdf['num'][i] #Longitude and latitude for each shapely point and the confluence number\n",
    "    if print_status: print(\"Lat/Lon/Confluence:\", lat, lon, num)\n",
    "    polyg[num], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "    if get_flow: \n",
    "        ffdata[num]= get_peaks(ff_json) #Use the function above to extract the json data\n",
    "        polyg[num]['features'][0]['ffcurve']=ffdata[num]\n",
    "    with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(num)), 'w') as f:\n",
    "       dump(polyg[num], f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 Polygon Files Found\n"
     ]
    }
   ],
   "source": [
    "poly_files=[] #Empty list to store the geojson paths\n",
    "ffdata={} \n",
    "\n",
    "poly_files=load_all_results(allresults)\n",
    "\n",
    "gdf=gpd.GeoDataFrame(crs={'init': 'epsg:{}'.format(use_epsg)})\n",
    "                          \n",
    "for _,filename in enumerate(poly_files):\n",
    "    num=re.findall('\\d+', filename)\n",
    "    temp_df=gpd.read_file(filename)\n",
    "    temp_df['ID_Num']=int(num[-1])\n",
    "    gdf=gdf.append(temp_df.iloc[0])\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        ffdata[num[-1]]=data['features'][0]['ffcurve']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0          1         10        100        101       102  \\\n",
      "RI                                                                        \n",
      "1.25  3269.042312  25.088418   7.003959   4.238119   4.167097  2.642965   \n",
      "1.5   3641.973430  30.849801   8.494574   5.113636   5.091586  3.243820   \n",
      "2.0   4080.529298  38.621843  10.485974   6.275664   6.358985  4.079904   \n",
      "5.0   5240.037297  60.316559  16.007592   9.530964   9.865393  6.406996   \n",
      "10.0  6025.059073  76.213688  20.017580  11.951031  12.410024  8.121865   \n",
      "\n",
      "            103        104         105        106    ...             90  \\\n",
      "RI                                                   ...                  \n",
      "1.25   6.959253   3.483064   46.896389   3.788126    ...      29.955113   \n",
      "1.5    8.489727   4.251320   56.757388   4.653818    ...      37.137951   \n",
      "2.0   10.540833   5.294715   69.570617   5.843961    ...      46.970890   \n",
      "5.0   16.306161   8.226494  105.276502   9.226237    ...      74.932082   \n",
      "10.0  20.595382  10.417623  131.398068  11.821790    ...      96.314980   \n",
      "\n",
      "             91           92         93         94         95           96  \\\n",
      "RI                                                                           \n",
      "1.25   7.936539  3265.959462  13.564102   7.690515  10.077885  3248.662001   \n",
      "1.5    9.844311  3649.539430  16.810411   9.510352  12.384218  3626.988220   \n",
      "2.0   12.486612  4102.259262  21.292720  12.030778  15.512085  4073.359885   \n",
      "5.0   20.077399  5297.451514  34.057282  19.176658  24.362534  5252.186795   \n",
      "10.0  26.013727  6107.023924  43.869586  24.625284  31.052907  6051.020294   \n",
      "\n",
      "             97         98         99  \n",
      "RI                                     \n",
      "1.25   4.103217   8.821614   4.531196  \n",
      "1.5    4.991966  10.792640   5.612118  \n",
      "2.0    6.194338  13.443601   7.117298  \n",
      "5.0    9.525784  20.922667  11.435218  \n",
      "10.0  11.942524  26.536442  14.811238  \n",
      "\n",
      "[5 rows x 559 columns]\n"
     ]
    }
   ],
   "source": [
    "if get_flow: ffdata_df=ff_summary(ffdata) #Run this function to construct the summary table for all outlet locations\n",
    "    \n",
    "if get_flow: ffdata_df.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) #Save the results as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sputnam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n"
     ]
    }
   ],
   "source": [
    "gdf.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) #Export the geodataframe as a shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
