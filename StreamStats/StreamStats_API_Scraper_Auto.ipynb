{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../USGStools')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state='NY' #The state abbreviation in uppercase\n",
    "\n",
    "path=r'C:\\Users\\sputnam\\Documents\\GitHub\\usgs-tools\\StreamStats\\results\\04150303' #Specify the location of the shapefile containing the lat/lon of points on the stream grid\n",
    "\n",
    "name='04150303_Confluences_Scoped.shp' #The name of the shapefile\n",
    "\n",
    "use_epsg='4326' #Specify a consistent coordinate reference system\n",
    "\n",
    "allresults=os.path.join(path,'AllStreamStats') #Location to save the StreamStats results for each polygon\n",
    "\n",
    "if os.path.isdir(allresults)==False: #If the desired path does not exist, create it.\n",
    "    os.mkdir(allresults)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf=gpd.read_file(os.path.join(path, name)) #Read the shapefile as a geopandas dataframe\n",
    "\n",
    "gdf=gdf.to_crs({'init': 'epsg:{0}'.format(use_epsg)}) #Transform the coordinate reference system of the geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/Lon/Confluence: 44.501949699941875 -75.51556623081206 401\n",
      "Fetched Peak Flows\n",
      "Lat/Lon/Confluence: 44.46446091702406 -75.52378465780414 402\n"
     ]
    }
   ],
   "source": [
    "polyg={} #Dictionary to store the catchment polygons (catchment boundaries) \n",
    "\n",
    "ffdata={} #Dictionary to store the outlet flow frequency data dictionaries\n",
    "\n",
    "get_flow=True\n",
    "print_status=True\n",
    "\n",
    "if state=='WI': get_flow=False \n",
    "\n",
    "start_confluence=401 #The confluence number to start. Normally set to zero unless there was an issue   \n",
    "\n",
    "for i in gdf[gdf[gdf['num']==start_confluence].index[0]:].index:\n",
    "    lon, lat, num = gdf.geometry[i].x, gdf.geometry[i].y, gdf['num'][i] #Longitude and latitude for each shapely point and the confluence number\n",
    "    if print_status: print(\"Lat/Lon/Confluence:\", lat, lon, num)\n",
    "    polyg[num], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "    if get_flow: \n",
    "        ffdata[num]= get_peaks(ff_json) #Use the function above to extract the json data\n",
    "        polyg[num]['features'][0]['ffcurve']=ffdata[num]\n",
    "    with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(num)), 'w') as f:\n",
    "       dump(polyg[num], f)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_files=[] #Empty list to store the geojson paths\n",
    "\n",
    "poly_files=load_all_results(allresults)\n",
    "\n",
    "gdf=gpd.GeoDataFrame(crs={'init': 'epsg:{}'.format(use_epsg)})\n",
    "                          \n",
    "for _,filename in enumerate(poly_files):\n",
    "    num=re.findall('\\d+', filename)\n",
    "    temp_df=gpd.read_file(filename)\n",
    "    temp_df['ID_Num']=int(num[-1])\n",
    "    gdf=gdf.append(temp_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_flow: ffdata_df=ff_summary(ffdata) #Run this function to construct the summary table for all outlet locations\n",
    "    \n",
    "if get_flow: ffdata_df.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) #Save the results as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) #Export the geodataframe as a shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
