{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamStats API Scraper Automatic\n",
    "\n",
    "__Description__: Tool to automatically run the [USGS StreamStats tool](https://www.usgs.gov/mission-areas/water-resources/science/streamstats-streamflow-statistics-and-spatial-analysis-tools?qt-science_center_objects=0#qt-science_center_objects) for multiple points within a catchment and return the flow frequency curves and subcatchment boundaries.\n",
    "\n",
    "__Input__: A shapefile containing the latitude and longitude of points on the stream grid for the specified state (confluence and main stem locations).\n",
    "\n",
    "__Output__: GeoJSON file containing the delinated catchment boundary and flow frequency data for each point, as well as a CSV file containing the flow frequency data.\n",
    "\n",
    "*Authors*: sputnam@Dewberry.com & slawler@Dewberry.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and Python options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../USGStools')\n",
    "from StreamStats_API_Scraper import*\n",
    "import geopandas as gpd\n",
    "from geojson import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the state abbreviation and location of the shapefile: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The state abbreviation in uppercase\n",
    "state='NY' \n",
    "\n",
    "#Specify the location of the shapefile containing the lat/lon of points on the stream grid\n",
    "path=r'C:\\Users\\tmiesse\\Work\\dewberry_stuff\\ryans_data\\orleans' \n",
    "name='confluences.shp' #The name of the shapefile\n",
    "\n",
    "#Specify a consistent coordinate reference system\n",
    "use_epsg='4326' \n",
    "\n",
    "#Location to save the StreamStats results for each polygon\n",
    "allresults=os.path.join(path,'AllStreamStats') \n",
    "if os.path.isdir(allresults)==False: \n",
    "    os.mkdir(allresults)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the shapefile as a geopandas dataframe\n",
    "#Transform the coordinate reference system of the geodataframe\n",
    "gdf=gpd.read_file(os.path.join(path, name)) \n",
    "gdf=gdf.to_crs({'init': 'epsg:{0}'.format(use_epsg)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store the catchment polygons (catchment boundaries) \n",
    "polyg={} \n",
    "\n",
    "#Dictionary to store the outlet flow frequency data dictionaries\n",
    "ffdata={} \n",
    "\n",
    "get_flow=True\n",
    "print_status=True\n",
    "if state=='WI': get_flow=False \n",
    "errors = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the API tool for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/Lon/Confluence: 43.329240955729645 -77.99522621186907 0.0\n",
      "Fetched Peak Flows\n",
      "Lat/Lon/Confluence: 43.3291219703773 -77.99633039437262 1.0\n",
      "Fetched Peak Flows\n",
      "could not process data 1.0\n",
      "Lat/Lon/Confluence: 43.328771969577375 -77.99594316471261 2.0\n",
      "Fetched Peak Flows\n",
      "Lat/Lon/Confluence: 43.328259629433404 -78.0051681153075 3.0\n",
      "Fetched Peak Flows\n",
      "could not process data 3.0\n",
      "Lat/Lon/Confluence: 43.328724619639736 -78.00802779532391 4.0\n",
      "Fetched Peak Flows\n",
      "could not process data 4.0\n",
      "Lat/Lon/Confluence: 43.32836493397188 -78.00801002958254 5.0\n"
     ]
    }
   ],
   "source": [
    "while errors != []:\n",
    "    errors = []\n",
    "    for i in gdf.index.values[:250]:\n",
    "        try:\n",
    "            #Longitude and latitude for each shapely point and the confluence number\n",
    "            lon, lat, ID_Num = gdf.geometry[i].x, gdf.geometry[i].y, gdf['ID_Num'][i] \n",
    "            if print_status: print(\"Lat/Lon/Confluence:\", lat, lon, ID_Num)\n",
    "                \n",
    "            #Run the SS_scrape function. Option: set status=False to hide print statements\n",
    "            polyg[ID_Num], ff_json  = SS_scrape(state, lon, lat, use_epsg, print_status) \n",
    "            if get_flow: \n",
    "                #Use the function above to extract the json data\n",
    "                ffdata[ID_Num]                           = get_peaks(ff_json) \n",
    "                polyg[ID_Num]['features'][0]['ffcurve']  = ffdata[ID_Num]\n",
    "            \n",
    "            with open(os.path.join(allresults,'StreamStats_Polygons_{0}.geojson'.format(int(ID_Num))), 'w') as f:\n",
    "                dump(polyg[ID_Num], f)\n",
    "        except:\n",
    "            print('could not process data {}'.format(gdf['ID_Num'][i]))\n",
    "            errors.append(gdf['ID_Num'][i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 Polygon Files Found\n"
     ]
    }
   ],
   "source": [
    "files=load_files(allresults)\n",
    "gdf, ffdic=load_results(files, use_epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The flow frequency data as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0           1          10         100        101          102  \\\n",
      "RI                                                                             \n",
      "1.25  275.936540  275.828738  279.523501  160.943822   5.228393   403.182882   \n",
      "1.5   319.878411  319.743587  324.633006  194.037752   6.443230   482.258700   \n",
      "2.0   374.407981  374.238640  380.674491  237.028873   8.116094   583.519117   \n",
      "5.0   519.825485  519.562349  530.266293  354.353897  12.784931   858.916767   \n",
      "10.0  620.072033  619.743144  633.503848  437.657095  16.205182  1055.023383   \n",
      "\n",
      "           104       105          106       107  ...         89         9  \\\n",
      "RI                                               ...                        \n",
      "1.25  1.944492  1.043198   403.556505  0.956855  ...   3.073012  1.831583   \n",
      "1.5   2.417815  1.293627   482.815746  1.185108  ...   3.813949  2.270821   \n",
      "2.0   3.084474  1.650115   584.327395  1.510184  ...   4.855562  2.891167   \n",
      "5.0   4.998262  2.655534   860.462941  2.426273  ...   7.799698  4.643868   \n",
      "10.0  6.488888  3.413349  1057.134887  3.117120  ...  10.022354  5.968405   \n",
      "\n",
      "            91         92        94        95          96         97  \\\n",
      "RI                                                                     \n",
      "1.25  2.210017   3.200154  1.477552  0.940434  161.594188   4.313454   \n",
      "1.5   2.744270   3.972418  1.814095  1.156934  194.678585   5.362334   \n",
      "2.0   3.498637   5.059508  2.280952  1.460278  237.633659   6.825177   \n",
      "5.0   5.636035   8.129937  3.579908  2.306623  354.784781  11.017468   \n",
      "10.0  7.259206  10.446641  4.527460  2.928900  437.917799  14.264474   \n",
      "\n",
      "               98        99  \n",
      "RI                           \n",
      "1.25   403.201436  2.128078  \n",
      "1.5    482.124282  2.636687  \n",
      "2.0    583.164481  3.354435  \n",
      "5.0    857.858577  5.381591  \n",
      "10.0  1053.360263  6.915521  \n",
      "\n",
      "[5 rows x 306 columns]\n"
     ]
    }
   ],
   "source": [
    "#Run this function to construct the summary table for all outlet locations\n",
    "if get_flow: ff_df=ff_summary(ffdic) \n",
    "    \n",
    "#Save the results as a csv\n",
    "if get_flow: ff_df.to_csv(os.path.join(path,'StreamStats_FlowFrequency.csv')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmiesse\\AppData\\Local\\Continuum\\anaconda3\\envs\\geoprocess\\lib\\site-packages\\geopandas\\io\\file.py:108: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n"
     ]
    }
   ],
   "source": [
    "#Export the geodataframe as a shapefile\n",
    "gdf.to_file(filename = os.path.join(path,'StreamStats_Polygons.shp')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The catchment polygons as a geojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'StreamStats_Polygons.geojson'), 'w') as f:\n",
    "     dump(gdf, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geoprocess]",
   "language": "python",
   "name": "conda-env-geoprocess-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
